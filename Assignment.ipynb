{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "# S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "# print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "# print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "# print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "    \n",
    "#     a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "#     a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "#     S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "#     ## PRINT CHESS BOARD AND VARIABLES\n",
    "#     print('')\n",
    "#     print(S)\n",
    "#     print(R,'', Done)\n",
    "#     print('check? ',env.check)\n",
    "#     print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "#     # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "#     if Done:\n",
    "#         break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "# S,X,allowed_a=env.Initialise_game()\n",
    "# N_episodes=1000\n",
    "\n",
    "# # VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "# R_save_random = np.zeros([N_episodes, 1])\n",
    "# N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "# for n in range(N_episodes):\n",
    "    \n",
    "#     S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "#     Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "#     i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "#     # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "#     while Done==0:\n",
    "        \n",
    "#         # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "#         a,_=np.where(allowed_a==1)\n",
    "#         a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "#         S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "#         if Done:\n",
    "            \n",
    "#             R_save_random[n]=np.copy(R)\n",
    "#             N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "#             break\n",
    "\n",
    "#         i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# # AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# # (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "# print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK... (Xavier initialisation)\n",
    "W1 = np.random.randn(N_h, N_in) * np.sqrt(1 / (N_in))\n",
    "W2 = np.random.randn(N_a, N_h) * np.sqrt(1 / (N_h))\n",
    "\n",
    "bias_W1 = np.zeros((N_h,))\n",
    "bias_W2 = np.zeros((N_a,))\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.00035       # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 20000 # THE NUMBER OF GAMES TO BE PLAYED\n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "AVG_R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n",
    "AVG_N_moves_save = np.zeros([N_episodes, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ddcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "\n",
    "    def __init__(self, Params, beta1):\n",
    "        \n",
    "        N_dim=np.shape(np.shape(Params))[0] # It finds out if the parameters given are in a vector (N_dim=1) or a matrix (N_dim=2)\n",
    "        \n",
    "        # INITIALISATION OF THE MOMENTUMS\n",
    "        if N_dim==1:\n",
    "               \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            \n",
    "            self.mt=np.zeros([self.N1])\n",
    "            self.vt=np.zeros([self.N1])\n",
    "        \n",
    "        if N_dim==2:\n",
    "            \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            self.N2=np.shape(Params)[1]\n",
    "        \n",
    "            self.mt=np.zeros([self.N1,self.N2])\n",
    "            self.vt=np.zeros([self.N1,self.N2])\n",
    "        \n",
    "        # HYPERPARAMETERS OF ADAM\n",
    "        self.beta1=beta1\n",
    "        self.beta2=0.999\n",
    "        \n",
    "        self.epsilon=10**(-8)\n",
    "        \n",
    "        # COUNTER OF THE TRAINING PROCESS\n",
    "        self.counter=0\n",
    "        \n",
    "        \n",
    "    def Compute(self,Grads):\n",
    "                \n",
    "        self.counter=self.counter+1\n",
    "        \n",
    "        self.mt=self.beta1*self.mt+(1-self.beta1)*Grads\n",
    "        \n",
    "        self.vt=self.beta2*self.vt+(1-self.beta2)*Grads**2\n",
    "        \n",
    "        mt_n=self.mt/(1-self.beta1**self.counter)\n",
    "        vt_n=self.vt/(1-self.beta2**self.counter)\n",
    "        \n",
    "        New_grads=mt_n/(np.sqrt(vt_n)+self.epsilon)\n",
    "        \n",
    "        return New_grads\n",
    "\n",
    "beta1=0.9 # First order momentum for Adam\n",
    "\n",
    "# Intialise Adam for the parameters\n",
    "Adam_W1=Adam(W1,beta1)\n",
    "Adam_W2=Adam(W2,beta1)\n",
    "\n",
    "Adam_bias_W1=Adam(bias_W1,beta1)\n",
    "Adam_bias_W2=Adam(bias_W2,beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.8572 Number of steps: 9.4661ps: 9.4661teps: 9.466523326166309\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    # print(n)                                 ## REMOVE THIS OF COURSE, WE USED THIS TO CHECK THAT IT WAS RUNNING\n",
    "\n",
    "    accumulated_reward = 0\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        \n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        a, _ = np.where(allowed_a==1) # list of allowed action indicies\n",
    "        # a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        # https://www.v7labs.com/blog/neural-networks-activation-functions#:~:text=ReLU%20activation%20function%20should%20only,(due%20to%20vanishing%20gradients).\n",
    "        # RELU activation should only be used in hidden layers\n",
    "        h1 = np.dot(W1,X)+bias_W1       # Neural activation: input layer -> hidden layer\n",
    "        x1 = h1*(h1>0)                  # Apply the RELU function\n",
    "        h2 = np.dot(W2,x1)+bias_W2      # Neural activation: hidden layer -> output layer\n",
    "        x2_Qvalues = 1/(1+np.exp(-h2))  # Apply the sigmoid function\n",
    "\n",
    "        # Epsilon-greedy parameter\n",
    "        # with probability epsilon choose action at random; if epsilon = 0 then always choose Greedy\n",
    "        eGreedy = int(np.random.rand() < epsilon_f) \n",
    "\n",
    "        # Implement the policy\n",
    "        if eGreedy:\n",
    "            # if Qvalues are the same or epsilon>0 (e-Greedy) choose action at random\n",
    "            a_agent = np.random.permutation(a)[0]\n",
    "        else:\n",
    "            # otherwise choose greedy. Will result in the action index which gives highest Q-value out of the possible actions\n",
    "            a_agent = a[np.argmax(x2_Qvalues[a])]\n",
    "            \n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "\n",
    "        accumulated_reward += R\n",
    "\n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            e_n = R - x2_Qvalues[a_agent]\n",
    "            \n",
    "            # Backpropagation: output layer -> hidden layer\n",
    "            delta2 = x2_Qvalues*(1-x2_Qvalues) * e_n\n",
    "            # delta2 = x2_Qvalues*np.heaviside(h2, 0.5) * e_n\n",
    "            \n",
    "            masked_delta2 = np.zeros_like(delta2)\n",
    "            masked_delta2[a_agent] = delta2[a_agent]\n",
    "            dW2 = np.outer(masked_delta2, x1)\n",
    "\n",
    "            # Backpropagation: hidden layer -> input layer\n",
    "            # delta1 = x1*np.heaviside(h1, 0.5) * np.dot(W2.T, masked_delta2)\n",
    "            delta1 = x1*(1-x1) * np.dot(W2.T, masked_delta2)\n",
    "            dW1 = np.outer(delta1, X)\n",
    "            \n",
    "            W2[a_agent] += eta*Adam_W2.Compute(dW2)[a_agent]\n",
    "            bias_W2[a_agent] += eta*Adam_bias_W2.Compute(masked_delta2)[a_agent]\n",
    "            W1 += eta*Adam_W1.Compute(dW1)\n",
    "            bias_W1 += eta*Adam_bias_W1.Compute(delta1)\n",
    "\n",
    "            R_save[n]=np.copy(accumulated_reward)\n",
    "            AVG_R_save[n] = np.sum(R_save)/(n+1)\n",
    "            N_moves_save[n]=np.copy(i)\n",
    "            AVG_N_moves_save[n] = np.sum(N_moves_save)/(n+1)\n",
    "\n",
    "            print('Episode',n,'finished. Average reward:',AVG_R_save[n][0],'Number of steps:',AVG_N_moves_save[n][0], end='\\r')\n",
    "            \n",
    "            break\n",
    "        \n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            a2, _ = np.where(allowed_a_next==1)\n",
    "\n",
    "            # SARSA target policy same as behaviour policy - epsilon greedy\n",
    "            eGreedy = int(np.random.rand() < epsilon_f)\n",
    "            if eGreedy:\n",
    "                a_agent2 = np.random.permutation(a2)[0]\n",
    "            else:\n",
    "                a_agent2 = a2[np.argmax(x2_Qvalues[a2])]\n",
    "\n",
    "            # Compute the error signal\n",
    "            # target/desired output - actual output\n",
    "            e_n = (R + gamma * x2_Qvalues[a_agent2]) - x2_Qvalues[a_agent]\n",
    "            \n",
    "            # Backpropagation: output layer -> hidden layer\n",
    "            delta2 = x2_Qvalues*(1-x2_Qvalues) * e_n\n",
    "            # delta2 = x2_Qvalues*np.heaviside(h2, 0.5) * e_n\n",
    "            \n",
    "            masked_delta2 = np.zeros_like(delta2)\n",
    "            masked_delta2[a_agent] = delta2[a_agent]\n",
    "            dW2 = np.outer(masked_delta2, x1)\n",
    "\n",
    "            # Backpropagation: hidden layer -> input layer\n",
    "            # delta1 = x1*np.heaviside(h1, 0.5) * np.dot(W2.T, masked_delta2)\n",
    "            delta1 = x1*(1-x1) * np.dot(W2.T, masked_delta2)\n",
    "            dW1 = np.outer(delta1, X)\n",
    "            \n",
    "            W2[a_agent] += eta*Adam_W2.Compute(dW2)[a_agent]\n",
    "            bias_W2[a_agent] += eta*Adam_bias_W2.Compute(masked_delta2)[a_agent]\n",
    "            W1 += eta*Adam_W1.Compute(dW1)\n",
    "            bias_W1 += eta*Adam_bias_W1.Compute(delta1)\n",
    "            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "print('Random_Agent, Average reward:',AVG_R_save[-1][0],'Number of steps:',AVG_N_moves_save[-1][0])\n",
    "\n",
    "# eta = 0.0001, draw=0\n",
    "\n",
    "# worse using heaviside function - implemented correctly\n",
    "# using a smaller penalty for moving (move=-0.01), allows the agent accumulate more reward\n",
    "\n",
    "# eta = 0.00035, 20000 episodes\n",
    "# 0.88, 7.2(base)\n",
    "# 0.81, 6.8 (move=-0.01)\n",
    "# 0.78, 8.7 (move=-0.01, draw=-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d0debf2040>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, N_episodes),AVG_R_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
